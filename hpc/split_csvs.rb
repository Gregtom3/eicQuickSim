#!/usr/bin/env ruby
# s3tools/split_project_csv.rb

require 'optparse'
require 'fileutils'
require 'csv'
require 'yaml'

# Default options: we require a project name and a number of rows per batch.
options = {
  num_files: nil,   # required: number of rows per batch
  name: nil         # required: project name
}

OptionParser.new do |opts|
  opts.banner = "Usage: split_project_csv.rb -n <project name> -f <nfiles per job>"

  opts.on("-n NAME", "--name=NAME", "Project name (required)") do |name|
    options[:name] = name
  end

  opts.on("-f NUM", "--num-files=NUM", Integer, "Number of rows per batch file (required)") do |num|
    options[:num_files] = num
  end

  opts.on("-h", "--help", "Displays Help") do
    puts opts
    exit
  end
end.parse!

# Validate required parameters.
if options[:name].nil? || options[:name].strip.empty?
  puts "Error: You must specify a project name with the -n option."
  exit 1
end

if options[:num_files].nil? || options[:num_files] <= 0
  puts "Error: You must specify a positive number for -f (nfiles per job)."
  exit 1
end

project_name = options[:name].strip
n_per_job    = options[:num_files]

# Define the base project directory: out/<project_name>
base_dir = File.join("out", project_name)
unless Dir.exist?(base_dir)
  puts "Error: Project directory #{base_dir} does not exist. Please create your project first."
  exit 1
end

# Global variable to store the user's batch directory overwrite choice.
overwrite_batches_choice = nil

# Process each configuration subdirectory (assumed names starting with "config_")
Dir.glob(File.join(base_dir, "config_*")).each do |config_dir|
  next unless File.directory?(config_dir)

  puts "Processing config directory: #{config_dir}"

  # Determine the 'batches' subdirectory.
  batch_dir = File.join(config_dir, "batches")
  if Dir.exist?(batch_dir)
    if overwrite_batches_choice.nil?
      print "Batches already exist in #{config_dir}. Remove old batches and create new ones? (y/n): "
      answer = STDIN.gets.strip.downcase
      if answer.start_with?("y")
        overwrite_batches_choice = true
        FileUtils.rm_rf(batch_dir)
        puts "Removed old batches in #{config_dir}."
      else
        overwrite_batches_choice = false
        puts "Skipping #{config_dir}..."
        next
      end
    else
      if overwrite_batches_choice
        FileUtils.rm_rf(batch_dir)
        puts "Removed old batches in #{config_dir} (global choice)."
      else
        puts "Skipping #{config_dir} (global choice: do not overwrite batches)."
        next
      end
    end
  end
  FileUtils.mkdir_p(batch_dir)

  # Look for the CSV file generated by preprocess_HPC in this config directory.
  input_csv = File.join(config_dir, "files.csv")
  unless File.exist?(input_csv)
    puts "Warning: #{input_csv} not found. Skipping this config directory."
    next
  end

  # Read the input CSV using headers.
  begin
    csv_data = CSV.read(input_csv, headers: true)
  rescue => e
    puts "Error reading #{input_csv}: #{e}"
    next
  end

  # Retrieve max_events from the config's CSV, if possible.
  max_event = if csv_data.headers.include?("n_events")
                csv_data.map { |row| row["n_events"].to_i rescue 0 }.max || 0
              else
                0
              end

  # Extract collision and energy configuration from the config directory name.
  # Assumes a directory name like "config_en_10x100" (collision: en, energy: 10x100)
  m = File.basename(config_dir).match(/config_([a-z]+)_(\d+x\d+)/)
  if m
    collision_type = m[1]
    energy_config  = m[2]
  else
    collision_type = "unknown"
    energy_config  = "unknown"
  end

  # Split the CSV into batches of n_per_job rows.
  batch_number = 1
  csv_data.each_slice(n_per_job) do |rows|
    batch_index = format('%04d', batch_number)
    batch_csv_path = File.join(batch_dir, "batch#{batch_index}.csv")
    puts "Writing #{batch_csv_path} with #{rows.size} rows..."

    # Write the batch CSV (include header)
    CSV.open(batch_csv_path, "w") do |csv|
      csv << csv_data.headers
      rows.each { |row| csv << row }
    end

    # Copy the weights file if it exists.
    weights_file_src = File.join(config_dir, "files_weights.csv")
    if File.exist?(weights_file_src)
      weights_file_dest = File.join(batch_dir, "batch#{batch_index}_weights.csv")
      FileUtils.cp(weights_file_src, weights_file_dest)
      puts "Copied weights file to #{weights_file_dest}"
    else
      puts "Warning: Weights file not found: #{weights_file_src}"
    end

    # Create a per-batch YAML configuration file for use by analysis macros.
    # This YAML file includes:
    #   analysis_type, energy_config, csv_source (global files.csv), max_events,
    #   collision_type, binning_scheme (fixed), and output_csv (unique per batch).
    yaml_config = {
      "analysis_type"  => "DIS",  # change if needed for different analysis types
      "energy_config"  => energy_config,
      "csv_source"     => File.expand_path(input_csv),
      "max_events"     => max_event,
      "collision_type" => collision_type,
      "binning_scheme" => "src/bins/example.yaml",
      "output_csv"     => File.join(config_dir, "analysis_DIS_#{collision_type}_#{energy_config}_batch#{batch_index}.csv")
    }
    batch_yaml_file = File.join(batch_dir, "batch#{batch_index}_config.yaml")
    File.open(batch_yaml_file, "w") do |file|
      file.write(YAML.dump(yaml_config))
    end
    puts "Created batch config YAML: #{batch_yaml_file}"

    batch_number += 1
  end

  puts "Finished processing #{input_csv}. Created #{batch_number - 1} batch files in #{batch_dir}."

  # --- Save MAX_EVENTS for this config from the config's CSV ---
  begin
    if csv_data.headers.include?("n_events")
      max_events_file = File.join(config_dir, "max_events.txt")
      File.open(max_events_file, "w") { |file| file.puts max_event }
      puts "Saved MAX_EVENTS value (#{max_event}) in #{max_events_file}"
    else
      puts "Warning: 'n_events' column not found in #{input_csv}. MAX_EVENTS file not created for #{config_dir}."
    end
  rescue => e
    puts "Error processing max events for #{config_dir}: #{e}"
  end

  puts "-" * 60
end

puts "CSV splitting completed successfully for project '#{project_name}'!"
